{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Introduction_to_DL.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c0033d671c7474290aa52af23e1ddf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a0163f8c2cc469f9b2b17970c3fbbab",
              "IPY_MODEL_003c301549b845fb8bda4158e330ab0e"
            ],
            "layout": "IPY_MODEL_a808620c173c43d9be7cd8f6898a342f"
          }
        },
        "5a0163f8c2cc469f9b2b17970c3fbbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": " 76%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1ce33782834a82a0eb4b59a4324a36",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ace21be813749e88b07c9bb8726cd77",
            "value": 7536640
          }
        },
        "003c301549b845fb8bda4158e330ab0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c97ee2c29d4860b5083ccd0ef8b063",
            "placeholder": "​",
            "style": "IPY_MODEL_37f591d5a9be47f780296e62c5a56996",
            "value": " 7536640/9912422 [09:03&lt;02:51, 13871.99it/s]"
          }
        },
        "a808620c173c43d9be7cd8f6898a342f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1ce33782834a82a0eb4b59a4324a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ace21be813749e88b07c9bb8726cd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "32c97ee2c29d4860b5083ccd0ef8b063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f591d5a9be47f780296e62c5a56996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC1TfEacFYfX"
      },
      "source": [
        "# Introduction to Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33mmXnSOGAb1"
      },
      "source": [
        "Notebook này sẽ có hướng dẫn về các mô hình cơ bản và được sử dụng rộng rãi trong Deep Learning:\n",
        "\n",
        "\n",
        "*   Fully Connected Neural Network\n",
        "*   Convolution Neural Network (CNN)\n",
        "*   Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9lqWnC5zocz"
      },
      "source": [
        "## Fully Connected Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCLOb0zOzmlb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTKPbqIh0NfW"
      },
      "source": [
        "class MyFullyConnectedLayer(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    \"\"\"Class này sử dụng fully connected layer (hay còn gọi là dense layer)\n",
        "\n",
        "    Args:\n",
        "    input_dim: Số chiều đầu vào\n",
        "    output_dim: Số chiều đầu ra\n",
        "    \"\"\"\n",
        "    super(MyFullyConnectedLayer, self).__init__()\n",
        "\n",
        "    # Khởi tạo fully connected layer\n",
        "    self.fc = nn.Linear(input_dim, output_dim)\n",
        "    # Khởi tạo activation function (ở đây sử dụng softmax)\n",
        "    self.activation = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"Đưa input qua fully connected layer và softmax để tính đầu ra\n",
        "    \"\"\"\n",
        "    # Đưa input qua fully connected layer\n",
        "    x = self.fc(x)\n",
        "    # Đưa qua softmax để tính score\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6VlQ67I0W9o",
        "outputId": "010a8685-74ea-4969-95b0-42abf7d0a2f9"
      },
      "source": [
        "# Khởi tạo mô hình neural network với \n",
        "# số chiều đầu vào là 128 và số chiều đầu ra là 3\n",
        "model = MyFullyConnectedLayer(input_dim=128, output_dim=3)\n",
        "# In ra model\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyFullyConnectedLayer(\n",
            "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (activation): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTCs6h9d_1zZ",
        "outputId": "4fa94958-7e39-49f9-f9ed-90628fc30c71"
      },
      "source": [
        "# Khởi tạo giá trị input ngẫu nhiên với 5 samples, mỗi sample có 128 chiều\n",
        "input_data = torch.randn(5, 128)\n",
        "# Đưa input qua mô hình\n",
        "out = model(input_data)\n",
        "# In ra kết quả\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1608, 0.6119, 0.2273],\n",
            "        [0.4622, 0.1974, 0.3405],\n",
            "        [0.4884, 0.2734, 0.2382],\n",
            "        [0.6227, 0.2992, 0.0781],\n",
            "        [0.1616, 0.7101, 0.1283]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TUNS7LhDsbo"
      },
      "source": [
        "## Multi layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIWwPR11AlvB"
      },
      "source": [
        "class MyFullyConnectedLayer(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    \"\"\"Class này xây dựng mô hình neural network với \n",
        "    1 input layer, 1 hidden layer và 1 output layer\n",
        "\n",
        "    Args:\n",
        "    input_dim: Số chiều đầu vào\n",
        "    hidden_dim: Số chiều tầng ẩn\n",
        "    output_dim: Số chiều đầu ra\n",
        "    \"\"\"\n",
        "    super(MyFullyConnectedLayer, self).__init__()\n",
        "\n",
        "    # Khởi tạo hidden layer với số chiều đầu vào bằng số  chiều của input\n",
        "    # và số chiều đầu ra bằng số chiều của tầng ẩn\n",
        "    self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
        "    # Khởi tạo relu activation function\n",
        "    self.relu = nn.ReLU()\n",
        "    # Khởi tạo output layer với số chiều đầu vào bằng số chiều của tầng ẩn\n",
        "    # và số chiều đầu ra bằng số chiều của ouput\n",
        "    self.output = nn.Linear(hidden_dim, output_dim)\n",
        "    # Khởi tạo softmax activation function\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"Đưa input qua 1 tầng hidden layer để tính đầu ra\n",
        "    \"\"\"\n",
        "    # Đưa input qua 1 tầng hidden layer, số chiều của x là (input_dim, hidden_dim)\n",
        "    x = self.hidden_layer(x)\n",
        "    # Đưa qua relu \n",
        "    x = self.relu(x)\n",
        "    # Đưa qua output layer, số chiều của x là (hidden_dim, output_dim)\n",
        "    x = self.output(x)\n",
        "    # Tính softmax\n",
        "    x = self.softmax(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYve5ltoFRYJ",
        "outputId": "712500e6-0105-45a2-8b89-c61c2adbabec"
      },
      "source": [
        "# Khởi tạo mô hình \n",
        "model = MyFullyConnectedLayer(input_dim=128, hidden_dim=256, output_dim=3)\n",
        "# In ra model\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyFullyConnectedLayer(\n",
            "  (hidden_layer): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6zRkFdIqrr0",
        "outputId": "b19505a7-0e32-4518-c75e-de9a06dc7cdd"
      },
      "source": [
        "# Khởi tạo giá trị input ngẫu nhiên với 5 samples, mỗi sample có 128 chiều\n",
        "input_data = torch.randn(5, 128)\n",
        "# Đưa input qua mô hình\n",
        "out = model(input_data)\n",
        "# In ra kết quả\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4862, 0.2722, 0.2416],\n",
            "        [0.4631, 0.2978, 0.2391],\n",
            "        [0.3661, 0.3545, 0.2794],\n",
            "        [0.3834, 0.3333, 0.2833],\n",
            "        [0.4253, 0.2373, 0.3374]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qDmwhjRH8Pu"
      },
      "source": [
        "## Training a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "2c0033d671c7474290aa52af23e1ddf2",
            "5a0163f8c2cc469f9b2b17970c3fbbab",
            "003c301549b845fb8bda4158e330ab0e",
            "a808620c173c43d9be7cd8f6898a342f",
            "4b1ce33782834a82a0eb4b59a4324a36",
            "6ace21be813749e88b07c9bb8726cd77",
            "32c97ee2c29d4860b5083ccd0ef8b063",
            "37f591d5a9be47f780296e62c5a56996"
          ]
        },
        "id": "cI_zRvwQFWeJ",
        "outputId": "919cfc2a-68b3-4cfe-da75-a815b6480ec0"
      },
      "source": [
        "# Hàm này dùng để đưa input về dạng Tensor và chuẩn hoá giá trị của ảnh về trong khoảng [0, 1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "# Download MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Chia data về từng batch có số lượng là 10\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c0033d671c7474290aa52af23e1ddf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-17f92e92b681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Download MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmnist_trainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmnist_testset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                         \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     )\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aql0siCYIJTk"
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "  \"\"\"Xây dựng mô hình với 2 hidden layers và 1 output layer. \n",
        "  Sử dụng ReLU activation sau mỗi hidden layer.\n",
        "  Sử dụng Softmax activation để đưa kết quả về dưới dạng xác suất.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "    self.hidden_1 = nn.Linear(28*28, 100) # (img_size, hidden_size_1) \n",
        "    self.hidden_2 = nn.Linear(100, 50) # (hidden_size_1, hidden_size_2)\n",
        "    self.output = nn.Linear(50, 10) # (hidden_size_2, num_output)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, img): \n",
        "    # Chuyển input dưới dạng ảnh 2 chiều (28, 28) thành vector 1 chiều (1, 28*28)\n",
        "    x = img.view(-1, 28*28)\n",
        "    # Đưa qua 1 tầng hidden layer và sử dụng relu \n",
        "    x = self.relu(self.hidden_1(x)) \n",
        "    x = self.relu(self.hidden_2(x))\n",
        "    # Đưa qua ouput layer và sử dụng softmax để đưa về xác suất\n",
        "    x = self.output(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "    \n",
        "model = MyModel() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8zCT2KiAMich",
        "outputId": "e891527e-4671-4e3a-acc8-c4315d117ba7"
      },
      "source": [
        "# Khởi tạo hàm loss, ở đây sử dụng Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Khởi tạo hàm tối ưu Adam với learning_rate là 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Khởi tạo số epoch\n",
        "epoch = 3\n",
        "\n",
        "# Bắt đầu training\n",
        "for epoch in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Lấy input từ data_loader, \n",
        "        # thông tin gồm ma trận 2 chiều (28, 28) của ảnh đầu vào\n",
        "        # và giá trị label của ảnh\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Đưa đạo hàm về giá trị 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Đưa input qua mô hình\n",
        "        outputs = model(inputs)\n",
        "        # Tính loss giữa output của mô hình và labels chuẩn\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Tính toán đạo hàm\n",
        "        loss.backward()\n",
        "        # Cập nhật đạo hàm\n",
        "        optimizer.step()\n",
        "\n",
        "        # In ra giá trị loss\n",
        "        total_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # In ra hàm loss với mỗi 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 2000))\n",
        "            total_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.748\n",
            "[1,  4000] loss: 1.667\n",
            "[1,  6000] loss: 1.655\n",
            "[2,  2000] loss: 1.644\n",
            "[2,  4000] loss: 1.637\n",
            "[2,  6000] loss: 1.606\n",
            "[3,  2000] loss: 1.541\n",
            "[3,  4000] loss: 1.539\n",
            "[3,  6000] loss: 1.536\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZZ0BIq2uNX-a",
        "outputId": "562e1ecc-c696-4f8c-a6b2-ec969710d9f6"
      },
      "source": [
        "# Số lượng đoán đúng\n",
        "correct = 0\n",
        "# Tổng số sample\n",
        "total = 0\n",
        "\n",
        "# Tính tỉ lệ mô hình dự đoán chính xác\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        x, y = data\n",
        "        output = model(x.view(-1, 28*28))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct +=1\n",
        "            total +=1\n",
        "print(f'accuracy: {round(correct/total, 3)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CIbsEaw8Qn5V",
        "outputId": "9d34c55b-2b1f-4b1d-c540-5065fc3475d0"
      },
      "source": [
        "# Hiển thị hình ảnh và dự đoán\n",
        "plt.imshow(x[2].view(28, 28))\n",
        "plt.show()\n",
        "print(torch.argmax(model(x[2].view(-1, 28*28))[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IsiElfJfG8U"
      },
      "source": [
        "## Convolutional Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dYgEvXbKRQ3O"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"Class này xây dựng mô hình CNN với 2 tầng convolution layers và max pooling ngay phía sau\n",
        "  Sau khi có feature map từ 2 tầng convolution, output sẽ tiếp tục đưa qua 2 tầng fully \n",
        "  connected layers và qua relu activation.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5) # 1 input channels, 6 output channels, kernel size = 5\n",
        "    self.pool = nn.MaxPool2d(2, 2) # kernel size = 2, stride = 2\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120) # tầng fully connected thứ nhất\n",
        "    self.fc2 = nn.Linear(120, 84) # tầng fully connected thứ hai\n",
        "    self.fc3 = nn.Linear(84, 10) # tầng fully connected thứ ba, cũng là output layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x))) # đưa qua tầng conv thứ nhất\n",
        "    x = self.pool(F.relu(self.conv2(x))) # đưa qua tầng conv thứ hai\n",
        "    x = x.view(-1, 16 * 5 * 5) # đưa input từ dạng nhiều chiều thành 1 chiều\n",
        "    x = F.relu(self.fc1(x)) # đưa qua tầng fully connected thứ nhất\n",
        "    x = F.relu(self.fc2(x)) # đưa qua tầng fully connected thứ hai\n",
        "    x = self.fc3(x) # lấy output\n",
        "    return x\n",
        "cnn_model = CNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VLyjHX7KgsH8",
        "outputId": "aefce33d-1f54-40c5-bda6-a53a1ebae1e9"
      },
      "source": [
        "# Khởi tạo hàm loss, ở đây sử dụng Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Khởi tạo hàm tối ưu Adam với learning_rate là 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Khởi tạo số epoch\n",
        "epoch = 3\n",
        "\n",
        "# Bắt đầu training\n",
        "for epoch in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Lấy input từ data_loader, \n",
        "        # thông tin gồm ma trận 2 chiều (28, 28) của ảnh đầu vào\n",
        "        # và giá trị label của ảnh\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Đưa đạo hàm về giá trị 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Đưa input qua mô hình\n",
        "        outputs = model(inputs)\n",
        "        # Tính loss giữa output của mô hình và labels chuẩn\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Tính toán đạo hàm\n",
        "        loss.backward()\n",
        "        # Cập nhật đạo hàm\n",
        "        optimizer.step()\n",
        "\n",
        "        # In ra giá trị loss\n",
        "        total_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # In ra hàm loss với mỗi 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 2000))\n",
        "            total_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.528\n",
            "[1,  4000] loss: 1.530\n",
            "[1,  6000] loss: 1.528\n",
            "[2,  2000] loss: 1.529\n",
            "[2,  4000] loss: 1.521\n",
            "[2,  6000] loss: 1.521\n",
            "[3,  2000] loss: 1.520\n",
            "[3,  4000] loss: 1.518\n",
            "[3,  6000] loss: 1.520\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p_GVbvfPhJBQ",
        "outputId": "a200527d-521f-4aa1-b03f-8368eca60975"
      },
      "source": [
        "# Số lượng đoán đúng\n",
        "correct = 0\n",
        "# Tổng số sample\n",
        "total = 0\n",
        "\n",
        "# Tính tỉ lệ mô hình dự đoán chính xác\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        x, y = data\n",
        "        output = model(x.view(-1, 28*28))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct +=1\n",
        "            total +=1\n",
        "print(f'accuracy: {round(correct/total, 3)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gu5_9jL2hMGl",
        "outputId": "65d9bcc3-d981-407d-a03f-4297d481b9b0"
      },
      "source": [
        "# Hiển thị hình ảnh và dự đoán\n",
        "plt.imshow(x[0].view(28, 28))\n",
        "plt.show()\n",
        "print(torch.argmax(model(x[0].view(-1, 28*28))[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9PbPOcWiq1u"
      },
      "source": [
        "## RNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rVSYmjIGtTSb"
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import string\n",
        "import unicodedata\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnZj-XGE4-4W"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q63nBsS3tVj2"
      },
      "source": [
        "# donwload và extract data \n",
        "fileurl = \"https://download.pytorch.org/tutorial/data.zip\"\n",
        "r = requests.get(fileurl)\n",
        "open(\"data.zip\", 'wb').write(r.content)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfTvtomK4B8a",
        "outputId": "862a4d77-849a-4ab9-f6e6-19a921ec7afd"
      },
      "source": [
        "# data file\n",
        "filepath = \"data/names/\"\n",
        "\n",
        "# Khởi tạo list chứa names và labels tương ứng\n",
        "line_list = []\n",
        "category_list = []\n",
        "\n",
        "# Store categories \n",
        "all_categories = []\n",
        "\n",
        "# Loop over all files in the directory and read them\n",
        "for filename in os.listdir(filepath):   \n",
        "  lines = open(filepath+filename, encoding = \"utf-8\").read().strip().split(\"\\n\")\n",
        "  line_list += lines\n",
        "  category = filename.split(\".\")[0]\n",
        "  all_categories.append(category)\n",
        "  categories = [category]*len(lines)\n",
        "  category_list += categories\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "print(\"Length of line/category lists: {}/{}\".format(len(line_list), len(category_list)))\n",
        "print(\"Number of categories:\", n_categories)\n",
        "print(\"Categories:\", all_categories)\n",
        "print(\"First 5 names:\", line_list[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of line/category lists: 20074/20074\n",
            "Number of categories: 18\n",
            "Categories: ['Vietnamese', 'Portuguese', 'Italian', 'Chinese', 'Korean', 'German', 'Russian', 'Polish', 'Arabic', 'French', 'Dutch', 'English', 'Czech', 'Irish', 'Japanese', 'Spanish', 'Scottish', 'Greek']\n",
            "First 5 names: ['Nguyen', 'Tron', 'Le', 'Pham', 'Huynh']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFurAdcz4hkb",
        "outputId": "8fe52d8a-4c9d-42e5-e218-7eecca8dfe5a"
      },
      "source": [
        "# Số lượng names cho từng language\n",
        "unique, counts = np.unique(category_list, return_counts=True)\n",
        "print(\"Names per language in training data:\\n\", dict(zip(unique, counts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Names per language in training data:\n",
            " {'Arabic': 2000, 'Chinese': 268, 'Czech': 519, 'Dutch': 297, 'English': 3668, 'French': 277, 'German': 724, 'Greek': 203, 'Irish': 232, 'Italian': 709, 'Japanese': 991, 'Korean': 94, 'Polish': 139, 'Portuguese': 74, 'Russian': 9408, 'Scottish': 100, 'Spanish': 298, 'Vietnamese': 73}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni9dKYeS5Hgq"
      },
      "source": [
        "### Convert names to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTUOXggP4zTt",
        "outputId": "8b1b6f12-5819-4cdb-c8ee-3f1f3f5156e1"
      },
      "source": [
        "# Tạo bộ vocab cho letters\n",
        "all_letters = string.ascii_letters + \" .,;'-\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "print(\"Vocabulary:\", all_letters)\n",
        "print(\"Vocabulary size:\", n_letters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
            "Vocabulary size: 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWtOjc55jID",
        "outputId": "cbc10d92-b710-4c11-b506-f5c662b084f3"
      },
      "source": [
        "# Chuyển từ định dạng unicode sang ascii, loại bỏ các kí tự dấu\n",
        "def unicode_to_ascii(s):\n",
        "  return \"\".join(\n",
        "    c for c in unicodedata.normalize(\"NFD\", s)\n",
        "    if unicodedata.category(c) != \"Mn\"\n",
        "    and c in all_letters\n",
        "  )\n",
        "\n",
        "# Example\n",
        "print(\"Example: Ślusàrski >>>\", unicode_to_ascii(\"Ślusàrski\"))\n",
        "print(\"Example: Ngân >>>\", unicode_to_ascii(\"Ngân\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example: Ślusàrski >>> Slusarski\n",
            "Example: Ngân >>> Ngan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "okmwH6mk5zga",
        "outputId": "54bcf416-03f6-4ad5-acf1-f54e8fc6b746"
      },
      "source": [
        "# Tìm giá trị index cho các letter\n",
        "def letter_to_index(letter):\n",
        "  return all_letters.find(letter)\n",
        "\n",
        "# Example\n",
        "print(\"Index of letter 'g':\", all_letters.find(\"g\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of letter 'g': 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVFBK4fQ6Ed5",
        "outputId": "e42bb00b-27f9-4b9b-92e4-bc0e03f7bc0c"
      },
      "source": [
        "# Chuyển name thành dạng one-hot vector\n",
        "def line_to_tensor(line):\n",
        "  tensor = torch.zeros(len(line), 1, n_letters)\n",
        "  for i, letter in enumerate(line):\n",
        "    tensor[i][0][letter_to_index(letter)] = 1\n",
        "  return tensor\n",
        "\n",
        "# Chuyển toàn bộ data thành dạng ascii và one-hot vectors\n",
        "line_list_clean = [unicode_to_ascii(line) for line in line_list]\n",
        "line_list_tensorized = [line_to_tensor(line) for line in line_list_clean] \n",
        "\n",
        "# Example\n",
        "print(\"Example name: Ngan\")\n",
        "print(\"Tensor size:\", line_to_tensor(\"Ngan\").size())\n",
        "print(\"Tensorized name:\\n\", line_to_tensor(\"Ngan\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example name: Ngan\n",
            "Tensor size: torch.Size([4, 1, 58])\n",
            "Tensorized name:\n",
            " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLFNyLnN7Emc"
      },
      "source": [
        "### Sequence padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzzi55Mq61-x",
        "outputId": "93a737ed-b298-4a3c-d6ea-21bfac46fc44"
      },
      "source": [
        "# tự động padding theo name có độ dài lớn nhất\n",
        "sequence_length = len(max(line_list, key=len))\n",
        "\n",
        "print(\"Longest name:\", max(line_list, key=len))\n",
        "print(\"Maximum sequence length:\", sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest name: Shirinsky-Shikhmatov\n",
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmZ-PE87aAq",
        "outputId": "94899777-e515-44ba-e375-7a8956e3f7b4"
      },
      "source": [
        "# Pad sequences\n",
        "line_tensor = pad_sequence(line_list_tensorized)\n",
        "\n",
        "# Chuyển tensor thành format thích hợp cho bước sau: Number of observations, 1, sequence length, features\n",
        "line_tensor_permuted = line_tensor.permute(1,2,0,3)\n",
        "\n",
        "print(\"Original shape:\", line_tensor.size())\n",
        "print(\"Permuted shape:\", line_tensor_permuted.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([20, 20074, 1, 58])\n",
            "Permuted shape: torch.Size([20074, 1, 20, 58])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcEkovs8J6E"
      },
      "source": [
        "### Create NamesDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v5IO57uS8DC3"
      },
      "source": [
        "# Chuyển tensor thành numpy array\n",
        "X = line_tensor_permuted.numpy()\n",
        "\n",
        "# Tạo dictionary để map các language thành dạng số\n",
        "category_dict = dict(zip(all_categories, range(n_categories)))\n",
        "\n",
        "# Chuyển toàn bộ label dạng text thành dạng số\n",
        "category_list_numeric = [category_dict.get(i) for i in category_list]\n",
        "y = np.array(category_list_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f87WSDSv8tHk"
      },
      "source": [
        "class NamesDataset():\n",
        "  \"\"\"Tạo NamesDataset dùng để chứa thông tin về input và label\n",
        "  \"\"\"\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = torch.from_numpy(features)\n",
        "    self.labels = torch.from_numpy(labels).type(torch.LongTensor)\n",
        "    self.len = len(features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "data_train = NamesDataset(features=X, labels=y)\n",
        "data_test = NamesDataset(features=X, labels=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxTZgoTk9Ii7"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T4mWJFtX88VO"
      },
      "source": [
        "# Batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Data loaders \n",
        "trainloader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhF11Wl9Yd6"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EiUxmAhn9r75"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)   # RNN\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)  \n",
        "    self.softmax = nn.LogSoftmax(dim=1)   # Log softmax\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Khởi tạo inital hidden\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "    # Đưa input và h0 qua RNN\n",
        "    out, _ = self.rnn(x, h0)\n",
        "    # Lấy output từ hidden state cuối cùng\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    # Log softmax output\n",
        "    out = self.softmax(out) \n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyecAIq4-kJs"
      },
      "source": [
        "### Training model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4pyoSF9WAA",
        "outputId": "55d6e1f6-bda5-4469-e8ef-19de8bfa2a6f"
      },
      "source": [
        "# Sử dụng GPU nếu có\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SHpwLRuq9mRV"
      },
      "source": [
        "# Các parameters của mô hình\n",
        "input_size = n_letters   # size of vocabulary\n",
        "hidden_size = 128 # hidden dim\n",
        "num_layers = 2 # số hidden layer\n",
        "num_classes = n_categories # số lượng languages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kq3O_xBe-iHN"
      },
      "source": [
        "# Khởi tạo mô hình\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes) \n",
        "\n",
        "# Gán mô hình với device (cpu hoặc gpu)\n",
        "model.to(device)\n",
        "\n",
        "# Traing hyper-parameters\n",
        "sequence_length = sequence_length   # length of padded tensors\n",
        "num_epochs = 50\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Print ra loss sau mỗi n step\n",
        "print_every = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD3rvc9y_INM",
        "outputId": "dc357847-03b6-4edd-dbba-67007a9183ac"
      },
      "source": [
        "# Bắt đầu training\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Start of traing -- Device: {} -- Epochs: {} -- Batches: {} -- Batch size: {}\"\n",
        "      .format(device, num_epochs, len(trainloader), batch_size))\n",
        "\n",
        "# Khởi tạo các biến dùng để tính loss, accuracy và visualize\n",
        "running_loss = 0\n",
        "running_total = 0\n",
        "running_correct = 0\n",
        "loss_list = [] \n",
        "loss_list_print_every = [] \n",
        "\n",
        "# Đưa model về training mode\n",
        "model.train()\n",
        "\n",
        "# Train model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (lines, labels) in enumerate(trainloader):\n",
        "        # Gán data vào device thính hợp\n",
        "        lines, labels = lines.to(device), labels.to(device)\n",
        "        \n",
        "        # Reshape batch cho phù hợp input của rnn\n",
        "        lines = lines.reshape(-1, sequence_length, input_size)\n",
        "        \n",
        "        # Forward and backward pass\n",
        "        output = model(lines)\n",
        "        loss = criterion(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tính loss và accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        running_total += labels.size(0)\n",
        "        running_correct += (predicted == labels).sum().item()       \n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # In ra loss và accuracy trung bình của mỗi mini-batch\n",
        "        if (i+1) % print_every == 0:         \n",
        "            print(\"Epoch: {}/{} -- Batches: {}/{} -- Training loss: {:.3f} -- Training accuracy: {:.3f}\"\n",
        "                  .format(epoch+1, num_epochs, i+1, len(trainloader), \n",
        "                          running_loss/print_every, running_correct/running_total))\n",
        "            \n",
        "            # Lưu running loss\n",
        "            loss_list_print_every.append(running_loss/print_every)\n",
        "            \n",
        "            # Reset running loss and accuracy\n",
        "            running_loss = 0\n",
        "            running_total = 0\n",
        "            running_correct = 0\n",
        "            \n",
        "print(\"Training complete. Total training time: {:.1f} seconds\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of traing -- Device: cpu -- Epochs: 50 -- Batches: 314 -- Batch size: 64\n",
            "Epoch: 1/50 -- Batches: 100/314 -- Training loss: 1.914 -- Training accuracy: 0.464\n",
            "Epoch: 1/50 -- Batches: 200/314 -- Training loss: 1.896 -- Training accuracy: 0.473\n",
            "Epoch: 1/50 -- Batches: 300/314 -- Training loss: 1.873 -- Training accuracy: 0.466\n",
            "Epoch: 2/50 -- Batches: 100/314 -- Training loss: 2.123 -- Training accuracy: 0.467\n",
            "Epoch: 2/50 -- Batches: 200/314 -- Training loss: 1.904 -- Training accuracy: 0.467\n",
            "Epoch: 2/50 -- Batches: 300/314 -- Training loss: 1.914 -- Training accuracy: 0.469\n",
            "Epoch: 3/50 -- Batches: 100/314 -- Training loss: 2.149 -- Training accuracy: 0.472\n",
            "Epoch: 3/50 -- Batches: 200/314 -- Training loss: 1.904 -- Training accuracy: 0.469\n",
            "Epoch: 3/50 -- Batches: 300/314 -- Training loss: 1.901 -- Training accuracy: 0.466\n",
            "Epoch: 4/50 -- Batches: 100/314 -- Training loss: 2.149 -- Training accuracy: 0.469\n",
            "Epoch: 4/50 -- Batches: 200/314 -- Training loss: 1.921 -- Training accuracy: 0.462\n",
            "Epoch: 4/50 -- Batches: 300/314 -- Training loss: 1.868 -- Training accuracy: 0.462\n",
            "Epoch: 5/50 -- Batches: 100/314 -- Training loss: 2.123 -- Training accuracy: 0.463\n",
            "Epoch: 5/50 -- Batches: 200/314 -- Training loss: 1.871 -- Training accuracy: 0.466\n",
            "Epoch: 5/50 -- Batches: 300/314 -- Training loss: 1.863 -- Training accuracy: 0.458\n",
            "Epoch: 6/50 -- Batches: 100/314 -- Training loss: 2.124 -- Training accuracy: 0.457\n",
            "Epoch: 6/50 -- Batches: 200/314 -- Training loss: 1.866 -- Training accuracy: 0.463\n",
            "Epoch: 6/50 -- Batches: 300/314 -- Training loss: 1.847 -- Training accuracy: 0.462\n",
            "Epoch: 7/50 -- Batches: 100/314 -- Training loss: 2.108 -- Training accuracy: 0.474\n",
            "Epoch: 7/50 -- Batches: 200/314 -- Training loss: 1.862 -- Training accuracy: 0.465\n",
            "Epoch: 7/50 -- Batches: 300/314 -- Training loss: 1.868 -- Training accuracy: 0.459\n",
            "Epoch: 8/50 -- Batches: 100/314 -- Training loss: 2.096 -- Training accuracy: 0.467\n",
            "Epoch: 8/50 -- Batches: 200/314 -- Training loss: 1.855 -- Training accuracy: 0.461\n",
            "Epoch: 8/50 -- Batches: 300/314 -- Training loss: 1.879 -- Training accuracy: 0.459\n",
            "Epoch: 9/50 -- Batches: 100/314 -- Training loss: 2.123 -- Training accuracy: 0.459\n",
            "Epoch: 9/50 -- Batches: 200/314 -- Training loss: 1.878 -- Training accuracy: 0.453\n",
            "Epoch: 9/50 -- Batches: 300/314 -- Training loss: 1.840 -- Training accuracy: 0.471\n",
            "Epoch: 10/50 -- Batches: 100/314 -- Training loss: 2.167 -- Training accuracy: 0.456\n",
            "Epoch: 10/50 -- Batches: 200/314 -- Training loss: 1.967 -- Training accuracy: 0.450\n",
            "Epoch: 10/50 -- Batches: 300/314 -- Training loss: 1.870 -- Training accuracy: 0.473\n",
            "Epoch: 11/50 -- Batches: 100/314 -- Training loss: 2.147 -- Training accuracy: 0.473\n",
            "Epoch: 11/50 -- Batches: 200/314 -- Training loss: 1.898 -- Training accuracy: 0.471\n",
            "Epoch: 11/50 -- Batches: 300/314 -- Training loss: 1.907 -- Training accuracy: 0.463\n",
            "Epoch: 12/50 -- Batches: 100/314 -- Training loss: 2.136 -- Training accuracy: 0.474\n",
            "Epoch: 12/50 -- Batches: 200/314 -- Training loss: 1.891 -- Training accuracy: 0.469\n",
            "Epoch: 12/50 -- Batches: 300/314 -- Training loss: 1.919 -- Training accuracy: 0.460\n",
            "Epoch: 13/50 -- Batches: 100/314 -- Training loss: 2.174 -- Training accuracy: 0.459\n",
            "Epoch: 13/50 -- Batches: 200/314 -- Training loss: 1.897 -- Training accuracy: 0.466\n",
            "Epoch: 13/50 -- Batches: 300/314 -- Training loss: 1.907 -- Training accuracy: 0.469\n",
            "Epoch: 14/50 -- Batches: 100/314 -- Training loss: 2.163 -- Training accuracy: 0.474\n",
            "Epoch: 14/50 -- Batches: 200/314 -- Training loss: 1.870 -- Training accuracy: 0.472\n",
            "Epoch: 14/50 -- Batches: 300/314 -- Training loss: 1.899 -- Training accuracy: 0.461\n",
            "Epoch: 15/50 -- Batches: 100/314 -- Training loss: 2.145 -- Training accuracy: 0.469\n",
            "Epoch: 15/50 -- Batches: 200/314 -- Training loss: 1.896 -- Training accuracy: 0.471\n",
            "Epoch: 15/50 -- Batches: 300/314 -- Training loss: 1.905 -- Training accuracy: 0.465\n",
            "Epoch: 16/50 -- Batches: 100/314 -- Training loss: 2.160 -- Training accuracy: 0.473\n",
            "Epoch: 16/50 -- Batches: 200/314 -- Training loss: 1.881 -- Training accuracy: 0.472\n",
            "Epoch: 16/50 -- Batches: 300/314 -- Training loss: 1.894 -- Training accuracy: 0.461\n",
            "Epoch: 17/50 -- Batches: 100/314 -- Training loss: 2.170 -- Training accuracy: 0.458\n",
            "Epoch: 17/50 -- Batches: 200/314 -- Training loss: 1.882 -- Training accuracy: 0.471\n",
            "Epoch: 17/50 -- Batches: 300/314 -- Training loss: 1.881 -- Training accuracy: 0.474\n",
            "Epoch: 18/50 -- Batches: 100/314 -- Training loss: 2.182 -- Training accuracy: 0.468\n",
            "Epoch: 18/50 -- Batches: 200/314 -- Training loss: 1.900 -- Training accuracy: 0.467\n",
            "Epoch: 18/50 -- Batches: 300/314 -- Training loss: 1.884 -- Training accuracy: 0.475\n",
            "Epoch: 19/50 -- Batches: 100/314 -- Training loss: 2.121 -- Training accuracy: 0.471\n",
            "Epoch: 19/50 -- Batches: 200/314 -- Training loss: 1.911 -- Training accuracy: 0.469\n",
            "Epoch: 19/50 -- Batches: 300/314 -- Training loss: 1.921 -- Training accuracy: 0.450\n",
            "Epoch: 20/50 -- Batches: 100/314 -- Training loss: 2.135 -- Training accuracy: 0.472\n",
            "Epoch: 20/50 -- Batches: 200/314 -- Training loss: 1.883 -- Training accuracy: 0.471\n",
            "Epoch: 20/50 -- Batches: 300/314 -- Training loss: 1.898 -- Training accuracy: 0.466\n",
            "Epoch: 21/50 -- Batches: 100/314 -- Training loss: 2.202 -- Training accuracy: 0.451\n",
            "Epoch: 21/50 -- Batches: 200/314 -- Training loss: 1.880 -- Training accuracy: 0.476\n",
            "Epoch: 21/50 -- Batches: 300/314 -- Training loss: 1.900 -- Training accuracy: 0.467\n",
            "Epoch: 22/50 -- Batches: 100/314 -- Training loss: 2.168 -- Training accuracy: 0.466\n",
            "Epoch: 22/50 -- Batches: 200/314 -- Training loss: 1.900 -- Training accuracy: 0.466\n",
            "Epoch: 22/50 -- Batches: 300/314 -- Training loss: 1.891 -- Training accuracy: 0.474\n",
            "Epoch: 23/50 -- Batches: 100/314 -- Training loss: 2.154 -- Training accuracy: 0.468\n",
            "Epoch: 23/50 -- Batches: 200/314 -- Training loss: 1.903 -- Training accuracy: 0.465\n",
            "Epoch: 23/50 -- Batches: 300/314 -- Training loss: 1.895 -- Training accuracy: 0.466\n",
            "Epoch: 24/50 -- Batches: 100/314 -- Training loss: 2.172 -- Training accuracy: 0.465\n",
            "Epoch: 24/50 -- Batches: 200/314 -- Training loss: 1.899 -- Training accuracy: 0.473\n",
            "Epoch: 24/50 -- Batches: 300/314 -- Training loss: 1.893 -- Training accuracy: 0.465\n",
            "Epoch: 25/50 -- Batches: 100/314 -- Training loss: 2.181 -- Training accuracy: 0.467\n",
            "Epoch: 25/50 -- Batches: 200/314 -- Training loss: 1.879 -- Training accuracy: 0.473\n",
            "Epoch: 25/50 -- Batches: 300/314 -- Training loss: 1.885 -- Training accuracy: 0.472\n",
            "Epoch: 26/50 -- Batches: 100/314 -- Training loss: 2.152 -- Training accuracy: 0.469\n",
            "Epoch: 26/50 -- Batches: 200/314 -- Training loss: 1.909 -- Training accuracy: 0.460\n",
            "Epoch: 26/50 -- Batches: 300/314 -- Training loss: 1.920 -- Training accuracy: 0.458\n",
            "Epoch: 27/50 -- Batches: 100/314 -- Training loss: 2.185 -- Training accuracy: 0.460\n",
            "Epoch: 27/50 -- Batches: 200/314 -- Training loss: 1.909 -- Training accuracy: 0.467\n",
            "Epoch: 27/50 -- Batches: 300/314 -- Training loss: 1.877 -- Training accuracy: 0.472\n",
            "Epoch: 28/50 -- Batches: 100/314 -- Training loss: 2.131 -- Training accuracy: 0.472\n",
            "Epoch: 28/50 -- Batches: 200/314 -- Training loss: 1.872 -- Training accuracy: 0.473\n",
            "Epoch: 28/50 -- Batches: 300/314 -- Training loss: 1.923 -- Training accuracy: 0.464\n",
            "Epoch: 29/50 -- Batches: 100/314 -- Training loss: 2.180 -- Training accuracy: 0.462\n",
            "Epoch: 29/50 -- Batches: 200/314 -- Training loss: 1.899 -- Training accuracy: 0.464\n",
            "Epoch: 29/50 -- Batches: 300/314 -- Training loss: 1.892 -- Training accuracy: 0.467\n",
            "Epoch: 30/50 -- Batches: 100/314 -- Training loss: 2.179 -- Training accuracy: 0.469\n",
            "Epoch: 30/50 -- Batches: 200/314 -- Training loss: 1.878 -- Training accuracy: 0.472\n",
            "Epoch: 30/50 -- Batches: 300/314 -- Training loss: 1.902 -- Training accuracy: 0.458\n",
            "Epoch: 31/50 -- Batches: 100/314 -- Training loss: 2.170 -- Training accuracy: 0.465\n",
            "Epoch: 31/50 -- Batches: 200/314 -- Training loss: 1.892 -- Training accuracy: 0.468\n",
            "Epoch: 31/50 -- Batches: 300/314 -- Training loss: 1.886 -- Training accuracy: 0.471\n",
            "Epoch: 32/50 -- Batches: 100/314 -- Training loss: 2.166 -- Training accuracy: 0.463\n",
            "Epoch: 32/50 -- Batches: 200/314 -- Training loss: 1.892 -- Training accuracy: 0.468\n",
            "Epoch: 32/50 -- Batches: 300/314 -- Training loss: 1.867 -- Training accuracy: 0.478\n",
            "Epoch: 33/50 -- Batches: 100/314 -- Training loss: 2.184 -- Training accuracy: 0.462\n",
            "Epoch: 33/50 -- Batches: 200/314 -- Training loss: 1.891 -- Training accuracy: 0.467\n",
            "Epoch: 33/50 -- Batches: 300/314 -- Training loss: 1.880 -- Training accuracy: 0.473\n",
            "Epoch: 34/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.469\n",
            "Epoch: 34/50 -- Batches: 200/314 -- Training loss: 1.915 -- Training accuracy: 0.470\n",
            "Epoch: 34/50 -- Batches: 300/314 -- Training loss: 1.868 -- Training accuracy: 0.471\n",
            "Epoch: 35/50 -- Batches: 100/314 -- Training loss: 2.146 -- Training accuracy: 0.469\n",
            "Epoch: 35/50 -- Batches: 200/314 -- Training loss: 1.866 -- Training accuracy: 0.473\n",
            "Epoch: 35/50 -- Batches: 300/314 -- Training loss: 1.916 -- Training accuracy: 0.465\n",
            "Epoch: 36/50 -- Batches: 100/314 -- Training loss: 2.183 -- Training accuracy: 0.466\n",
            "Epoch: 36/50 -- Batches: 200/314 -- Training loss: 1.878 -- Training accuracy: 0.473\n",
            "Epoch: 36/50 -- Batches: 300/314 -- Training loss: 1.897 -- Training accuracy: 0.464\n",
            "Epoch: 37/50 -- Batches: 100/314 -- Training loss: 2.151 -- Training accuracy: 0.469\n",
            "Epoch: 37/50 -- Batches: 200/314 -- Training loss: 1.893 -- Training accuracy: 0.467\n",
            "Epoch: 37/50 -- Batches: 300/314 -- Training loss: 1.903 -- Training accuracy: 0.471\n",
            "Epoch: 38/50 -- Batches: 100/314 -- Training loss: 2.170 -- Training accuracy: 0.470\n",
            "Epoch: 38/50 -- Batches: 200/314 -- Training loss: 1.870 -- Training accuracy: 0.468\n",
            "Epoch: 38/50 -- Batches: 300/314 -- Training loss: 1.916 -- Training accuracy: 0.460\n",
            "Epoch: 39/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.464\n",
            "Epoch: 39/50 -- Batches: 200/314 -- Training loss: 1.876 -- Training accuracy: 0.472\n",
            "Epoch: 39/50 -- Batches: 300/314 -- Training loss: 1.889 -- Training accuracy: 0.467\n",
            "Epoch: 40/50 -- Batches: 100/314 -- Training loss: 2.177 -- Training accuracy: 0.468\n",
            "Epoch: 40/50 -- Batches: 200/314 -- Training loss: 1.926 -- Training accuracy: 0.457\n",
            "Epoch: 40/50 -- Batches: 300/314 -- Training loss: 1.847 -- Training accuracy: 0.477\n",
            "Epoch: 41/50 -- Batches: 100/314 -- Training loss: 2.144 -- Training accuracy: 0.473\n",
            "Epoch: 41/50 -- Batches: 200/314 -- Training loss: 1.895 -- Training accuracy: 0.456\n",
            "Epoch: 41/50 -- Batches: 300/314 -- Training loss: 1.896 -- Training accuracy: 0.474\n",
            "Epoch: 42/50 -- Batches: 100/314 -- Training loss: 2.169 -- Training accuracy: 0.470\n",
            "Epoch: 42/50 -- Batches: 200/314 -- Training loss: 1.872 -- Training accuracy: 0.476\n",
            "Epoch: 42/50 -- Batches: 300/314 -- Training loss: 1.908 -- Training accuracy: 0.459\n",
            "Epoch: 43/50 -- Batches: 100/314 -- Training loss: 2.181 -- Training accuracy: 0.458\n",
            "Epoch: 43/50 -- Batches: 200/314 -- Training loss: 1.873 -- Training accuracy: 0.472\n",
            "Epoch: 43/50 -- Batches: 300/314 -- Training loss: 1.901 -- Training accuracy: 0.468\n",
            "Epoch: 44/50 -- Batches: 100/314 -- Training loss: 2.172 -- Training accuracy: 0.465\n",
            "Epoch: 44/50 -- Batches: 200/314 -- Training loss: 1.905 -- Training accuracy: 0.463\n",
            "Epoch: 44/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.472\n",
            "Epoch: 45/50 -- Batches: 100/314 -- Training loss: 2.156 -- Training accuracy: 0.462\n",
            "Epoch: 45/50 -- Batches: 200/314 -- Training loss: 1.884 -- Training accuracy: 0.466\n",
            "Epoch: 45/50 -- Batches: 300/314 -- Training loss: 1.896 -- Training accuracy: 0.466\n",
            "Epoch: 46/50 -- Batches: 100/314 -- Training loss: 2.142 -- Training accuracy: 0.475\n",
            "Epoch: 46/50 -- Batches: 200/314 -- Training loss: 1.904 -- Training accuracy: 0.465\n",
            "Epoch: 46/50 -- Batches: 300/314 -- Training loss: 1.940 -- Training accuracy: 0.462\n",
            "Epoch: 47/50 -- Batches: 100/314 -- Training loss: 2.187 -- Training accuracy: 0.464\n",
            "Epoch: 47/50 -- Batches: 200/314 -- Training loss: 1.905 -- Training accuracy: 0.469\n",
            "Epoch: 47/50 -- Batches: 300/314 -- Training loss: 1.859 -- Training accuracy: 0.474\n",
            "Epoch: 48/50 -- Batches: 100/314 -- Training loss: 2.149 -- Training accuracy: 0.470\n",
            "Epoch: 48/50 -- Batches: 200/314 -- Training loss: 1.899 -- Training accuracy: 0.468\n",
            "Epoch: 48/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.468\n",
            "Epoch: 49/50 -- Batches: 100/314 -- Training loss: 2.141 -- Training accuracy: 0.471\n",
            "Epoch: 49/50 -- Batches: 200/314 -- Training loss: 1.897 -- Training accuracy: 0.472\n",
            "Epoch: 49/50 -- Batches: 300/314 -- Training loss: 1.914 -- Training accuracy: 0.456\n",
            "Epoch: 50/50 -- Batches: 100/314 -- Training loss: 2.138 -- Training accuracy: 0.476\n",
            "Epoch: 50/50 -- Batches: 200/314 -- Training loss: 1.926 -- Training accuracy: 0.458\n",
            "Epoch: 50/50 -- Batches: 300/314 -- Training loss: 1.888 -- Training accuracy: 0.461\n",
            "Training complete. Total training time: 424.0 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHMNcV2YAO2M"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pZYrpK6K_M_z",
        "outputId": "7ce1f043-ee4e-444d-c1ab-7a183de8406e"
      },
      "source": [
        "running_loss = 0\n",
        "labels_true = np.array([], dtype=int)\n",
        "labels_pred = np.array([], dtype=int)\n",
        "\n",
        "# Đưa model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():   # Không tính đạo hàm   \n",
        "    for i, (lines, labels) in enumerate(testloader):\n",
        "        lines, labels = lines.to(device), labels.to(device)\n",
        "        lines = lines.reshape(-1, sequence_length, input_size).to(device)\n",
        "        \n",
        "        # Đưa input vào model\n",
        "        output = model(lines)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)      \n",
        "\n",
        "        # Tính accuracy\n",
        "        labels_true = np.append(labels_true, labels.cpu().numpy())\n",
        "        labels_pred = np.append(labels_pred, predicted.cpu().numpy())\n",
        "\n",
        "        \n",
        "test_accuracy = np.equal(labels_pred, labels_true).mean()         \n",
        "        \n",
        "print(\"Evaluating network on {} images in test set -- Test loss: {:.3f} -- Test accuracy: {:.3f}\"\n",
        "      .format(len(testloader.dataset), running_loss/len(testloader), test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating network on 20074 images in test set -- Test loss: 1.942 -- Test accuracy: 0.469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MetjIi6UCiGI"
      },
      "source": [
        "### Accuracy per category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yv1F4d1lClSe",
        "outputId": "7d81c90e-2e61-41e3-f883-6296e5450847"
      },
      "source": [
        "# Xây dựng ma trận 2 chiều rỗng để chứa kết quả\n",
        "cm = np.zeros((num_classes, num_classes))\n",
        "\n",
        "# Tạo confusion matrix\n",
        "for i in range(len(labels_true)):\n",
        "    cm[labels_true[i]][labels_pred[i]] +=1\n",
        "\n",
        "for i in range(num_classes):\n",
        "    cm[i] = cm[i] / cm[i].sum()\n",
        "\n",
        "print(\"Accuracy by category:\")\n",
        "acc_dict = dict(zip(all_categories, [round(i, 2) for i in (cm.diagonal())]))\n",
        "for i in range(len(acc_dict)):\n",
        "    print(list(acc_dict.keys())[i], \":\", list(acc_dict.values())[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy by category:\n",
            "Vietnamese : 0.0\n",
            "Portuguese : 0.0\n",
            "Italian : 0.0\n",
            "Chinese : 0.0\n",
            "Korean : 0.0\n",
            "German : 0.0\n",
            "Russian : 1.0\n",
            "Polish : 0.0\n",
            "Arabic : 0.0\n",
            "French : 0.0\n",
            "Dutch : 0.0\n",
            "English : 0.0\n",
            "Czech : 0.0\n",
            "Irish : 0.0\n",
            "Japanese : 0.0\n",
            "Spanish : 0.0\n",
            "Scottish : 0.0\n",
            "Greek : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tgvzaobnCmI4"
      },
      "source": [
        "# Dự đoán một tên bất kì\n",
        "def predict(input_line, n_predictions=3):\n",
        "  input_tensorized = line_to_tensor(unicode_to_ascii(input_line))\n",
        "  num_zeros = sequence_length - len(input_line)\n",
        "  zeros = torch.zeros(num_zeros, 1, n_letters)\n",
        "  input_tensorized = torch.cat((input_tensorized, zeros), dim = 0)\n",
        "  input_tensorized = input_tensorized.permute(1,0,2)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    input_tensorized = input_tensorized.to(device)\n",
        "    output = model(input_tensorized)\n",
        "    output = torch.exp(output)\n",
        "    topv, topi = output.topk(n_predictions)\n",
        "\n",
        "  print(\">\", input_line, \"\\nLanguage -- Class Probability\")\n",
        "  for i in range(n_predictions):\n",
        "    value = topv[0][i].item()\n",
        "    category_index = topi[0][i].item()\n",
        "    category = all_categories[category_index]\n",
        "    print(\"{} -- {:.2f}%\".format(category, value*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7P5OKrEGf-F",
        "outputId": "7dcfb884-a80b-4275-ebba-c9712cc3dc6e"
      },
      "source": [
        "test_name = \"Aguilera\"\n",
        "predict(test_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Aguilera \n",
            "Language -- Class Probability\n",
            "Russian -- 61.49%\n",
            "English -- 9.19%\n",
            "Arabic -- 8.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VKeSjNKFGpJ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}