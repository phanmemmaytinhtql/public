<!DOCTYPE html>
<!-- saved from url=(0067)https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>How Naive Bayes Classifiers Work – with Python Code Examples</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism.min.css">
    <link rel="stylesheet" type="text/css" href="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-unescaped-markup.css">

    <link href="./How Naive Bayes Classifiers Work – with Python Code Examples_files/css" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="./How Naive Bayes Classifiers Work – with Python Code Examples_files/screen.css">
    <link rel="stylesheet" type="text/css" href="./How Naive Bayes Classifiers Work – with Python Code Examples_files/algolia-search.css">

    <script type="text/javascript" async="" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/analytics.js"></script><script async="" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/gtm.js"></script><script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/algoliasearch.min.js"></script>
    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/autocomplete.min.js"></script>

    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/main.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/footer.js"></script>

    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/main(1).js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/footer(1).js"></script>

    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/main(2).js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/footer(2).js"></script>

    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/setup-locale.js"></script>


    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/dayjs.min.js"></script>
    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/localizedFormat.min.js"></script>
    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/relativeTime.min.js"></script>

    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/zh-cn.min.js"></script>


    <link rel="icon" href="https://www.freecodecamp.org/news/favicon.png" type="image/png">
    <link rel="canonical" href="https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/amp/">
    
    <meta property="og:site_name" content="freeCodeCamp.org">
    <meta property="og:type" content="article">
    <meta property="og:title" content="How Naive Bayes Classifiers Work – with Python Code Examples">
    <meta property="og:description" content="Naive Bayes Classifiers (NBC) are simple yet powerful Machine Learning algorithms. They are based on conditional probability and Bayes&#39;s Theorem.  In this post, I explain &amp;quot;the trick&amp;quot; behind NBC and I&#39;ll give you an example that we can use to solve a classification problem.  In the next sections,">
    <meta property="og:url" content="https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/">
    <meta property="og:image" content="https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ">
    <meta property="article:published_time" content="2020-11-03T00:28:32.000Z">
    <meta property="article:modified_time" content="2020-11-03T01:02:45.000Z">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Algorithms">
    
    <meta property="article:publisher" content="https://www.facebook.com/freecodecamp">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="How Naive Bayes Classifiers Work – with Python Code Examples">
    <meta name="twitter:description" content="Naive Bayes Classifiers (NBC) are simple yet powerful Machine Learning algorithms. They are based on conditional probability and Bayes&#39;s Theorem.  In this post, I explain &amp;quot;the trick&amp;quot; behind NBC and I&#39;ll give you an example that we can use to solve a classification problem.  In the next sections,">
    <meta name="twitter:url" content="https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/">
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Jose J. Rodríguez">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="Machine Learning, Algorithms">
    <meta name="twitter:site" content="@freecodecamp">
    <meta name="twitter:creator" content="@josejorgexl">
    <meta property="og:image:width" content="2000">
    <meta property="og:image:height" content="1332">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "freeCodeCamp.org",
        "url": "https://www.freecodecamp.org/news/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://www.freecodecamp.org/news/content/images/2019/11/fcc_primary_large_24X210.svg",
            "width": 210,
            "height": 24
        }
    },
    "author": {
        "@type": "Person",
        "name": "Jose J. Rodríguez",
        "image": {
            "@type": "ImageObject",
            "url": "https://www.freecodecamp.org/news/content/images/2020/11/IMG_20170725_124841.jpg",
            "width": 1536,
            "height": 2048
        },
        "url": "https://www.freecodecamp.org/news/author/jose/",
        "sameAs": [
            "https://jj.hashnode.dev",
            "https://twitter.com/josejorgexl"
        ]
    },
    "headline": "How Naive Bayes Classifiers Work – with Python Code Examples",
    "url": "https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/",
    "datePublished": "2020-11-03T00:28:32.000Z",
    "dateModified": "2020-11-03T01:02:45.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ",
        "width": 2000,
        "height": 1332
    },
    "keywords": "Machine Learning, Algorithms",
    "description": "Naive Bayes Classifiers (NBC) are simple yet powerful Machine Learning\nalgorithms. They are based on conditional probability and Bayes&#x27;s Theorem.\n\nIn this post, I explain &quot;the trick&quot; behind NBC and I&#x27;ll give you an example that\nwe can use to solve a classification problem.\n\nIn the next sections, I&#x27;ll be talking about the math behind NBC. Feel free to\nskip those sections and go to the implementation part if you are not interested\nin the math.\n\nIn the implementation section, I&#x27;ll show you a simple",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://www.freecodecamp.org/news/"
    }
}
    </script>

    <meta name="generator" content="Ghost 3.39">
    <link rel="alternate" type="application/rss+xml" title="freeCodeCamp.org" href="https://www.freecodecamp.org/news/rss/">
    <!-- This is related to https://webmonetization.org/ -->
<meta name="monetization" content="$ilp.uphold.com/LJmbPn7WD4JB">
<!-- GAP -->


<!-- Google Tag Manager -->
<script>
  // Set up dataLayer with data if provided
  window.dataLayer = window.dataLayer || [{ gaPropertyId: 'UA-55446531-20' }];

  // Initialized GTM via gtag
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-55446531-20');

  // Configure and initialize GTM
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl+'&gtm_cookies_win=x';f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer', 'GTM-5D6RKKP');
</script>
<!-- End Google Tag Manager -->


<meta name="google-site-verification" content="b4tITLzEeeZGEpvD4mGNf3khKM4fvqejQaz9SYBQP8E">

<style id="fit-vids-style">.fluid-width-video-container{flex-grow: 1;width:100%;}.fluid-width-video-wrapper{width:100%;position:relative;padding:0;}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper object,.fluid-width-video-wrapper embed {position:absolute;top:0;left:0;width:100%;height:100%;}</style></head>

<body class="post-template tag-machine-learning tag-algorithms">

    <div class="site-wrapper">
        <nav class="site-nav nav-padding">
    <div class="site-nav-left">
        <form id="search-form" onsubmit="submitSearch()">
  <div role="search" class="searchbox__wrapper">
    <input type="search" placeholder="Search 6,000+ tutorials" id="search-input" class="aa-input" autocomplete="off" spellcheck="false" role="combobox" aria-autocomplete="list" aria-expanded="true" aria-owns="algolia-autocomplete-listbox-0" dir="auto" style=""><pre aria-hidden="true" style="position: absolute; visibility: hidden; white-space: pre; font-family: Lato, sans-serif; font-size: 18px; font-style: normal; font-variant: normal; font-weight: 400; word-spacing: 0px; letter-spacing: normal; text-indent: 0px; text-rendering: auto; text-transform: none;"></pre>
    <button type="submit" title="Submit your search query." class="ais-SearchBox-submit">
      <svg class="ais-SearchBox-submitIcon" xmlns="https://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 40 40">
        <path d="M26.804 29.01c-2.832 2.34-6.465 3.746-10.426 3.746C7.333 32.756 0 25.424 0 16.378 0 7.333 7.333 0 16.378 0c9.046 0 16.378 7.333 16.378 16.378 0 3.96-1.406 7.594-3.746 10.426l10.534 10.534c.607.607.61 1.59-.004 2.202-.61.61-1.597.61-2.202.004L26.804 29.01zm-10.426.627c7.323 0 13.26-5.936 13.26-13.26 0-7.32-5.937-13.257-13.26-13.257C9.056 3.12 3.12 9.056 3.12 16.378c0 7.323 5.936 13.26 13.258 13.26z"></path>
      </svg>
    </button>
    <div id="dropdown-container"><span class="algolia-autocomplete" style="position: absolute; z-index: 100; direction: ltr; display: none; width: 449.797px; top: 32px; left: 25px;"><span class="aa-dropdown-menu" role="listbox" id="algolia-autocomplete-listbox-0" style="display: block; left: 0px; right: auto;"><div class="aa-dataset-1"></div></span></span></div>
  </div>
</form>

<script>
  const client = algoliasearch('QMJYL5WYTI', '4318af87aa3ce128708f1153556c6108');
  const index = client.initIndex(main['algolia-index-name']);
  const screenWidth = window.screen.width;
  const screenHeight = window.screen.height;
  const hitsToRender = (screenWidth >= 767 && screenHeight >= 768) ? 8 : 5;
  const searchForm = document.getElementById('search-form');
  const input = document.getElementById('search-input');
  const dropdownContainer = document.getElementById('dropdown-container');
  let searchQuery, hitSelected, hits;

  input.addEventListener('input', e => {
    searchQuery = e.target.value;
  });

  // Prevent form from being submitted with magnifying
  // glass or enter when there is no query or hits
  searchForm.addEventListener('submit', e => {
    e.preventDefault();

    submitSearch();
  });

  const search = autocomplete('#search-input', { 
      hint: false,
      keyboardShortcuts: ['s', 191],
      openOnFocus: true,
      appendTo: dropdownContainer,
      debug: true // allow tabbing through results
    }, [
    {
      source: autocomplete.sources.hits(index, { hitsPerPage: hitsToRender }),
      debounce: 250,
      templates: {
        suggestion: (suggestion, result) => {
          hits = true;
          return `
            <a href="${suggestion.url}">
              <div class="algolia-result">
                <span>${suggestion._highlightResult.title.value}</span>
              </div>
            </a>
          `;
        },
        empty: (options) => {
          hits = false;
          return `
            <div class="aa-suggestion footer-suggestion no-hits-footer">
              <div class="algolia-result">
                <span>
                  No tutorials found
                </span>
              </div>
            </div>
          `;
        },
        footer: (query, result) => {
          if (!query.isEmpty) {
            return `
              <div class="aa-suggestion footer-suggestion">
                <a id="algolia-footer-selector" href="https://www.freecodecamp.org/news/search?query=${searchQuery}">
                  <div class="algolia-result algolia-footer">
                    <span>See all results for ${searchQuery}</span>
                  </div>
                </a>
              </div>
            `;
          }
        }
      }
    }
  ]).on('autocomplete:selected', (event, suggestion, dataset, context) => {
    // If article is selected, set to URL of the article. 
    // If footer is selected, set to search results path
    hitSelected = suggestion ? suggestion.url : `https://www.freecodecamp.org/news/search?query=${searchQuery}`;

    // Let browser handle click, and do not go to selection on tab key press
    if (context.selectionMethod === 'click' || context.selectionMethod === 'tabKey') {
      return;
    }

    // Go to selected article or footer path
    if (hits) {
      window.location.assign(hitSelected);
    }
  });

  // Go to highlighted hit or search for current query
  // when magnifying glass or enter is pressed
  function submitSearch() {
    hitSelected = document.getElementsByClassName('aa-cursor')[0];

    if (hitSelected && searchQuery) {
      const articleUrl = hitSelected.querySelector('a').href;
      window.location.assign(articleUrl);
    } else if (!hitSelected && searchQuery && hits) {
      window.location.assign(`https://www.freecodecamp.org/news/search?query=${searchQuery}`);
    }
  }

  // close dropbar when clicking off 
  document.addEventListener('click', e => {
    if (e.target !== input) {
      search.autocomplete.close();
    }
  });
</script>
    </div>
    <div class="site-nav-middle">
        <a class="site-nav-logo" href="https://www.freecodecamp.org/news"><img src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/fcc_primary_large_24X210.svg" alt="freeCodeCamp.org"></a>
    </div>
    <div class="site-nav-right">
        <div class="nav-group">
            <a class="nav-forum" id="nav-forum" rel="noopener noreferrer" target="_blank" href="https://forum.freecodecamp.org/">Forum</a>

            <a class="toggle-button-nav" id="nav-donate" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/donate/">
                Donate
            </a>
        </div>

    </div>
</nav>


        <a class="banner" id="banner" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/">
    <p>
        Learn to code — <span>free 3,000-hour curriculum</span>
    </p>
</a>


        <div id="error-message"></div>

        




<main id="site-main" class="site-main outer">
    <div class="inner">

        <article class="post-full post tag-machine-learning tag-algorithms ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="November 2, 2020">November 2, 2020</time>
                    <span class="date-divider">/</span>
                    <a href="https://www.freecodecamp.org/news/tag/machine-learning/">
                        #Machine Learning
                    </a>
                </section>
                <h1 class="post-full-title">How Naive Bayes Classifiers Work – with Python Code Examples</h1>
            </header>

            <div class="post-full-author-header">


                
<section class="author-card">
    <img class="author-profile-image" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/IMG_20170725_124841.jpg" alt="Jose J. Rodríguez">
    <section class="author-card-content author-card-content-no-bio">
        <h4 class="author-card-name"><a href="https://www.freecodecamp.org/news/author/jose/">Jose J. Rodríguez</a></h4>
    </section>
</section>


            </div>

            <figure class="post-full-image">
                <img srcset="https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1604082477708-ca2b52322107?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/photo-1604082477708-ca2b52322107" alt="How Naive Bayes Classifiers Work – with Python Code Examples" onerror="this.style.display=&#39;none&#39;">
            </figure>

            <section class="post-full-content">
                <div class="post-content">
                    <!--kg-card-begin: markdown--><p>Naive Bayes Classifiers (NBC) are simple yet powerful Machine Learning algorithms. They are based on conditional probability and Bayes's Theorem.</p>
<p>In this post, I explain "the trick" behind NBC and I'll give you an example that we can use to solve a classification problem.</p>
<p>In the next sections, I'll be talking about the math behind NBC. Feel free to skip those sections and go to the implementation part if you are not interested in the math.</p>
<p>In the implementation section, I'll show you a simple NBC algorithm. Then we'll use it to solve a classification problem. The task will be to determine whether a certain passenger on the Titanic survived the accident or not.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="conditionalprobability">Conditional probability</h2>
<p>Before talking about the algorithm itself, let's talk about the simple math behind it. We need to understand what conditional probability is and how can we use Bayes's Theorem to calculate it.</p>
<p>Think about a fair die with six sides. What's the probability of getting a six when rolling the die? That's easy, it's 1/6. We have six possible and equally likely outcomes but we are interested in just one of them. So, 1/6 it is.</p>
<p>But what happens if I tell you that I have rolled the die already and the outcome is an even number? What's the probability that we have got a six now?</p>
<p>This time, the possible outcomes are just three because there are only three even numbers on the die. We are still interested in just one of those outcomes, so now the probability is greater: 1/3. What's the difference between both cases?</p>
<p>In the first case, we had no <strong>prior</strong> information about the outcome. Thus, we needed to consider every single possible result.</p>
<p>In the second case, we were told that the outcome was an even number, so we could reduce the space of possible outcomes to just the three even numbers that appear in a regular six-sided die.</p>
<p>In general, when calculating the probability of an event A, given the occurrence of another event B, we say we are calculating the <strong>conditional probability</strong> of A given B, or just the probability of A given B. We denote it <code>P(A|B)</code>.</p>
<p>For example, the probability of getting a six given that the number we have got is even: <code>P(Six|Even) = 1/3</code>. Here we, denoted with <strong>Six</strong> the event of getting a six and with <strong>Even</strong> the event of getting an even number.</p>
<p>But, how do we calculate conditional probabilities? Is there a formula?</p>
<h2 id="howtocalculateconditionalprobsandbayesstheorem">How to calculate conditional probs and Bayes's Theorem</h2>
<p>Now, I'll give you a couple of formulas to calculate conditional probs. I promise they won't be hard, and they are important if you want to understand the insights of the Machine Learning algorithms we'll be talking about later.</p>
<p>The probability of an event A given the occurrence of another event B can be calculated as follows:</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(A|B) = P(A,B)/P(B)
</code></pre>
<p>Where <code>P(A,B)</code> denotes the probability of both A and B occurring at the same time, and <code>P(B)</code> denotes the probability of B.</p>
<p>Notice that we need <code>P(B) &gt; 0</code> because it makes no sense to talk about the probability of A given B if the occurrence of B is not possible.</p>
<p>We can also calculate the probability of an event A, given the occurrence of multiple events B1, B2,..., Bn:</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(A|B1,B2,...,Bn) = P(A,B1,B2,...,Bn)/P(B1,B2,...,Bn)
</code></pre>
<p>There's another way of calculating conditional probs. This way is the so-called Bayes's Theorem.</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(A|B) = P(B|A)P(A)/P(B)

P(A|B1,B2,...,Bn) = P(B1,B2,...,Bn|A)P(A)/P(B1,B2,...,Bn)
</code></pre>
<p>Notice that we are calculating the probability of event A given the event B, by <em>inverting</em> the order of occurence of the events.</p>
<p>Now we suppose the event A has occurred and we want to calculate the prob of event B (or events B1,B2,...,Bn in the second and more general example).</p>
<p>An important fact that can be derived from this Theorem is the formula to calculate <code>P(B1,B2,...,Bn,A)</code>. That's called the chain rule for probabilities.</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(B1,B2,...,Bn,A) = P(B1 | B2, B3, ..., Bn, A)P(B2,B3,...,Bn,A)
= P(B1 | B2, B3, ..., Bn, A)P(B2 | B3, B4, ..., Bn, A)P(B3, B4, ..., Bn, A)
= P(B1 | B2, B3, ..., Bn, A)P(B2 | B3, B4, ..., Bn, A)...P(Bn | A)P(A)
</code></pre>
<p>That's an ugly formula, isn't it? But under some conditions we can make a workaround and avoid it.</p>
<p>Let's talk about the last concept we need to know to understand the algorithms.</p>
<h2 id="independence">Independence</h2>
<p>The last concept we are going to talk about is independence. We say events A and B are independent if</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(A|B) = P(A)
</code></pre>
<p>That means that the prob of event A is not affected by the occurrence of event B. A direct consequence is that <code>P(A,B) = P(A)P(B)</code>.</p>
<p>In plain English, this means that the prob of the occurrence of both A and B at the same time is equal to the product of the probs of events A and B occurring separately.</p>
<p>If A and B are independent, it also holds that:</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(A,B|C) = P(A|C)P(B|C)
</code></pre>
<p>Now we are ready to talk about Naive Bayes Classifiers!</p>
<h2 id="naivebayesclassifiers">Naive Bayes Classifiers</h2>
<p>Suppose we have a vector <strong>X</strong> of <em>n</em> features and we want to determine the class of that vector from a set of <em>k</em> classes <em>y1, y2,...,yk</em>. For example, if we want to determine whether it'll rain today or not.</p>
<p>We have two possible classes (<em>k = 2</em>): <em>rain</em>, <em>not rain</em>, and the length of the vector of features might be 3 (<em>n = 3</em>).</p>
<p>The first feature might be whether it is cloudy or sunny, the second feature could be whether humidity is high or low, and the third feature would be whether the temperature is high, medium, or low.</p>
<p>So, these could be possible feature vectors.</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">&lt;Cloudy, H_High, T_Low&gt;
&lt;Sunny, H_Low, T_Medium&gt;
&lt;Cloudy, H_Low, T_High&gt;
</code></pre>
<p>Our task is to determine whether it'll rain or not, given the weather features.</p>
<p>After learning about conditional probabilities, it seems natural to approach the problem by trying to calculate the prob of raining given the features:</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">R = P(Rain | Cloudy, H_High, T_Low)
NR = P(NotRain | Cloudy, H_High, T_Low)
</code></pre>
<p>If <code>R &gt; NR</code> we answer that it'll rain, otherwise we say it won't.</p>
<p>In general, if we have <em>k</em> classes <em>y1, y2, ..., yk</em>, and a vector of <em>n</em> features <strong>X = &lt;X1, X2, ..., Xn&gt;</strong>, we want to find the class <em>yi</em> that maximizes</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">P(yi | X1, X2, ..., Xn) = P(X1, X2,..., Xn, yi)/P(X1, X2, ..., Xn)
</code></pre>
<p>Notice that the denominator is constant and it does not depend on the class <em>yi</em>. So, we can ignore it and just focus on the numerator.</p>
<p>In a previous section, we saw how to calculate <code>P(X1, X2,..., Xn, yi)</code> by decomposing it in a product of conditional probabilities (the ugly formula):</p>
<pre><code>P(X1, X2,..., Xn, yi) = P(X1 | X2,..., Xn, yi)P(X2 | X3,..., Xn, yi)...P(Xn | yi)P(yi)
</code></pre>
<p>Assuming all the features <strong>Xi</strong> are independent and using Bayes's Theorem, we can calculate the conditional probability as follows:</p>
<pre><code>P(yi | X1, X2,..., Xn) = P(X1, X2,..., Xn | yi)P(yi)/P(X1, X2, ..., Xn)
= P(X1 | yi)P(X2 | yi)...P(Xn | yi)P(yi)/P(X1, X2, ..., Xn)
</code></pre>
<p>And we just need to focus on the numerator.</p>
<p>By finding the class <em>yi</em> that maximizes the previous expression, we are classifying the input vector. But, how can we get all those probabilities?</p>
<h2 id="howtocalculatetheprobabilities">How to calculate the probabilities</h2>
<p>When solving these kind of problems we need to have a set of previously classified examples.</p>
<p>For instance, in the problem of guessing whether it'll rain or not, we need to have several examples of feature vectors and their classifications that they would be obtained from past weather forecasts.</p>
<p>So, we would have something like this:</p>
<pre class=" language-pseudocode"><code class=" language-pseudocode">...
&lt;Cloudy, H_High, T_Low&gt; -&gt; Rain
&lt;Sunny, H_Low, T_Medium&gt; -&gt; Not Rain
&lt;Cloudy, H_Low, T_High&gt; -&gt; Not Rain
...
</code></pre>
<p>Suppose we need to classify a new vector <code>&lt;Coudy, H_Low, T_Low&gt;</code>. We need to calculate:</p>
<pre><code>P(Rain | Cloudy, H_Low, T_Low) = P(Cloudy | H_Low, T_Low, Rain)P(H_Low | T_Low, Rain)P(T_Low | Rain)P(Rain)/P(Cloudy, H_Low, T_Low)
</code></pre>
<p>We get the previous expression by applying the definition of conditional probability and the chain rule. Remember we only need to focus on the numerator so we can drop the denominator.</p>
<p>We also need to calculate the prob for <code>NotRain</code>, but we can do this in a similar way.</p>
<p>We can find <code>P(Rain) = # Rain/Total</code>. That means counting the entries in the dataset that are classified with <em>Rain</em> and dividing that number by the size of the dataset.</p>
<p>To calculate <code>P(Cloudy | H_Low, T_Low, Rain)</code> we need to count all the entries that have the features <em>H_Low, T_Low</em> and <em>Cloudy</em>. Those entries also need to be classified as <code>Rain</code>. Then, that number is divided by the total amount of data. We calculate the rest of the factors of the formula in a similar fashion.</p>
<p>Making those computations for every possible class is very expensive and slow. So we need to make assumptions about the problem that simplify the calculations.</p>
<p>Naive Bayes Classifiers assume that all the features are independent from each other. So we can rewrite our formula applying Bayes's Theorem and assuming independence between every pair of features:</p>
<pre><code>P(Rain | Cloudy, H_Low, T_Low) = P(Cloudy | Rain)P(H_Low | Rain)P(T_Low | Rain)P(Rain)/P(Cloudy, H_Low, T_Low)
</code></pre>
<p>Now we calculate <code>P(Cloudy | Rain)</code> counting the number of entries that are classified as <code>Rain</code> and were <code>Cloudy</code>.</p>
<blockquote>
<p>The algorithm is called <em>Naive</em> because of this independence assumption. There are dependencies between the features most of the time. We can't say that in real life there isn't a dependency between the humidity and the temperature, for example. Naive Bayes Classifiers are also called Independence Bayes, or Simple Bayes.</p>
</blockquote>
<p>The general formula would be:</p>
<pre><code>P(yi | X1, X2, ..., Xn) = P(X1 | yi)P(X2 | yi)...P(Xn | yi)P(yi)/P(X1, X2, ..., Xn)
</code></pre>
<p>Remember you can get rid of the denominator. We only calculate the numerator and answer the class that maximizes it.</p>
<p>Now, let's implement our NBC and let's use it in a problem.</p>
<h2 id="letscode">Let's code!</h2>
<p>I will show you an implementation of a simple NBC and then we'll see it in practice.</p>
<p>The problem we are going to solve is determining whether a passenger on the Titanic survived or not, given some features like their gender and their age.</p>
<p>Here you can see the implementation of a very simple NBC:</p>
<pre class=" language-python"><code class=" language-python"><span class="token keyword">class</span> <span class="token class-name">NaiveBayesClassifier</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token triple-quoted-string string">'''
        X and y denotes the features and the target labels respectively
        '''</span>
        self<span class="token punctuation">.</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">=</span> X<span class="token punctuation">,</span> y 
        
        self<span class="token punctuation">.</span>N <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">)</span> <span class="token comment"># Length of the training set</span>

        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># Dimension of the vector of features</span>

        self<span class="token punctuation">.</span>attrs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># Here we'll store the columns of the training set</span>

        self<span class="token punctuation">.</span>output_dom <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token comment"># Output classes with the number of ocurrences in the training set. In this case we have only 2 classes</span>

        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># To store every row [Xi, yi]</span>
        
        
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># if we have never seen this value for this attr before, </span>
                <span class="token comment"># then we add it to the attrs array in the corresponding position</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>attrs<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>attrs<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    
            <span class="token comment"># if we have never seen this output class before,</span>
            <span class="token comment"># then we add it to the output_dom and count one occurrence for now</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>output_dom<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>output_dom<span class="token punctuation">[</span>self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
            <span class="token comment"># otherwise, we increment the occurrence of this output in the training set by 1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>output_dom<span class="token punctuation">[</span>self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
            <span class="token comment"># store the row</span>
            self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            
            

    <span class="token keyword">def</span> <span class="token function">classify</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> entry<span class="token punctuation">)</span><span class="token punctuation">:</span>

        solve <span class="token operator">=</span> <span class="token boolean">None</span> <span class="token comment"># Final result</span>
        max_arg <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token comment"># partial maximum</span>

        <span class="token keyword">for</span> y <span class="token keyword">in</span> self<span class="token punctuation">.</span>output_dom<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

            prob <span class="token operator">=</span> self<span class="token punctuation">.</span>output_dom<span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token operator">/</span>self<span class="token punctuation">.</span>N <span class="token comment"># P(y)</span>

            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
                cases <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>data <span class="token keyword">if</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> entry<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">and</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">]</span> <span class="token comment"># all rows with Xi = xi</span>
                n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cases<span class="token punctuation">)</span>
                prob <span class="token operator">*=</span> n<span class="token operator">/</span>self<span class="token punctuation">.</span>N <span class="token comment"># P *= P(Xi = xi)</span>
                
            <span class="token comment"># if we have a greater prob for this output than the partial maximum...</span>
            <span class="token keyword">if</span> prob <span class="token operator">&gt;</span> max_arg<span class="token punctuation">:</span>
                max_arg <span class="token operator">=</span> prob
                solve <span class="token operator">=</span> y

        <span class="token keyword">return</span> solve
</code></pre>
<p>Here, we assume every feature has a discrete domain. That means they take a value from a finite set of possible values.</p>
<p>The same happens with classes. Notice that we store some data in the <code>__init__</code> method so we don't need to repeat some operations. The classification of a new entry is carried on in the <code>classify</code> method.</p>
<blockquote>
<p>This is a simple example of an implementation. In real world applications you don't need (and is better if you don't make) your own implementation. For example, the <code>sklearn</code> library in Python contains several good implementations of NBC's.</p>
</blockquote>
<p>Notice how easy it is to implement it!</p>
<p>Now, let's apply our new classifier to solve a problem. We have a dataset with the description of 887 passengers on the Titanic. We also can see whether a given passenger survived the tragedy or not.</p>
<p>So our task is to determine if another passenger that is not included in the training set made it or not.</p>
<p>In this example, I'll be using the <code>pandas</code> library to read and process the data. I don't use any other tool.</p>
<p>The data is stored in a file called <em>titanic.csv</em>, so the first step is to read the data and get an overview of it.</p>
<pre class=" language-python"><code class=" language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'titanic.csv'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>The output is:</p>
<pre class=" language-text"><code class=" language-text">Survived  Pclass                                               Name  \
0         0       3                             Mr. Owen Harris Braund   
1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   
2         1       3                              Miss. Laina Heikkinen   
3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   
4         0       3                            Mr. William Henry Allen   

      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  
0    male  22.0                        1                        0   7.2500  
1  female  38.0                        1                        0  71.2833  
2  female  26.0                        0                        0   7.9250  
3  female  35.0                        1                        0  53.1000  
4    male  35.0                        0                        0   8.0500  
</code></pre>
<p>Notice we have the Name of each passenger. We won't use that feature for our classifier because it is not significant for our problem. We'll also get rid of the Fare feature because it is continuous and our features need to be discrete.</p>
<blockquote>
<p>There are Naive Bayes Classifiers that support continuous features. For example, the Gaussian Naive Bayes Classifier.</p>
</blockquote>
<pre class=" language-python"><code class=" language-python">y <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> v<span class="token punctuation">:</span> <span class="token string">'yes'</span> <span class="token keyword">if</span> v <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'no'</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># target values as string</span>

<span class="token comment"># We won't use the 'Name' nor the 'Fare' field</span>

X <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">,</span> <span class="token string">'Sex'</span><span class="token punctuation">,</span> <span class="token string">'Age'</span><span class="token punctuation">,</span> <span class="token string">'Siblings/Spouses Aboard'</span><span class="token punctuation">,</span> <span class="token string">'Parents/Children Aboard'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values <span class="token comment"># features values</span>
</code></pre>
<p>Then, we need to separate our data set in a training set and a validation set. The later is used to validate how well our algorithm is doing.</p>
<pre class=" language-python"><code class=" language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># &gt;&gt; 887</span>

<span class="token comment"># We'll take 600 examples to train and the rest to the validation process</span>
y_train <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">600</span><span class="token punctuation">]</span>
y_val <span class="token operator">=</span> y<span class="token punctuation">[</span><span class="token number">600</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

X_train <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">600</span><span class="token punctuation">]</span>
X_val <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token number">600</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
</code></pre>
<p>We create our NBC with the training set and then classify every entry in the validation set.</p>
<p>We measure the accuracy of our algorithm by dividing the number of entries it correctly classified by the total number of entries in the validation set.</p>
<pre class=" language-python"><code class=" language-python"><span class="token comment">## Creating the Naive Bayes Classifier instance with the training data</span>

nbc <span class="token operator">=</span> NaiveBayesClassifier<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>


total_cases <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>y_val<span class="token punctuation">)</span> <span class="token comment"># size of validation set</span>

<span class="token comment"># Well classified examples and bad classified examples</span>
good <span class="token operator">=</span> <span class="token number">0</span>
bad <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>total_cases<span class="token punctuation">)</span><span class="token punctuation">:</span>
    predict <span class="token operator">=</span> nbc<span class="token punctuation">.</span>classify<span class="token punctuation">(</span>X_val<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#     print(y_val[i] + ' --------------- ' + predict)</span>
    <span class="token keyword">if</span> y_val<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> predict<span class="token punctuation">:</span>
        good <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        bad <span class="token operator">+=</span> <span class="token number">1</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'TOTAL EXAMPLES:'</span><span class="token punctuation">,</span> total_cases<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RIGHT:'</span><span class="token punctuation">,</span> good<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'WRONG:'</span><span class="token punctuation">,</span> bad<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'ACCURACY:'</span><span class="token punctuation">,</span> good<span class="token operator">/</span>total_cases<span class="token punctuation">)</span>
</code></pre>
<p>The output:</p>
<pre><code>TOTAL EXAMPLES: 287
RIGHT: 200
WRONG: 87
ACCURACY: 0.6968641114982579
</code></pre>
<p>It's not great but it's something. We can get about a 10% accuracy improvement if we get rid of other features like <em>Siblings/Spouses Aboard</em> and <em>Parents/Children Aboard</em>.</p>
<p>You can see a notebook with the code and the dataset <a href="https://github.com/josejorgers/naive-bayes-classifier-example">here</a></p>
<h2 id="conclusions">Conclusions</h2>
<p>Today, we have neural networks and other complex and expensive ML algorithms all over the place.</p>
<p>NBCs are very simple algorithms that let us achieve good results in some classification problems without needing a lot of resources. They also scale very well, which means we can add a lot more features and the algorithm will still be fast and reliable.</p>
<p>Even in a case where NBCs were not a good fit for the problem we were trying to solve, they might be very useful as a baseline.</p>
<p>We could first try to solve the problem using an NBC with a few lines of code and little effort. Then we could try to achieve better results with more complex and expensive algorithms.</p>
<p>This process can save us a lot of time and gives us an immediate feedback about whether complex algorithms are really worth it for our task.</p>
<p>In this article you read about conditional probabilities, independence, and Bayes's Theorem. Those are the Mathematical concepts behind Naive Bayes Classifiers.</p>
<p>After that, we saw a simple implementation of an NBC and solved the problem of determining whether a passenger on the Titanic survived the accident.</p>
<p>I hope you found this article useful. You can read about Computer Science related topics in my <a href="https://jj.hashnode.dev/">personal blog</a> and by following me on <a href="https://twitter.com/josejorgexl">Twitter</a>.</p>
<!--kg-card-end: markdown-->
                </div>
                <hr>

                <div class="post-full-author-header">
                    
<section class="author-card">
    <img class="author-profile-image" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/IMG_20170725_124841.jpg" alt="Jose J. Rodríguez">
    <section class="author-card-content">
        <h4 class="author-card-name"><a href="https://www.freecodecamp.org/news/author/jose/">Jose J. Rodríguez</a></h4>
        <p>Computer Scientist. Teaching Probabilities and Statistics at the University of Havana. Also researching in the field of Combinatorial Optimization.</p>
    </section>
</section>


                </div>
                <hr>

                <p class="social-row">

    If you read this far, tweet to the author to show them you care. <a id="tweet-btn" class="cta-button">Tweet a thanks</a>
</p>

                
<div class="learn-cta-row">
    <p>
        Learn to code for free. freeCodeCamp's open source curriculum has helped more than 40,000 people get jobs as developers. <a class="cta-button" id="learn-to-code-cta" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/learn/">Get started</a>
    </p>
</div>

                  <script>
    // Conditionally show comments section based on publication language setting
    const showCommentsList = ['zh-cn'];

    if (showCommentsList.includes(`en`)) {
      const hostname = window.location.hostname;
      const discourseEmbedMap = {
        'www.freecodecamp.org': {
          file: 'https://forum.freecodecamp.org/srv/status',
          discourseUrl: 'https://forum.freecodecamp.org/'
        },
        'chinese.freecodecamp.org': {
          file: 'https://chinese.freecodecamp.org/forum/srv/status',
          discourseUrl: 'https://chinese.freecodecamp.org/forum/',
        },
        'dev': {
          file: 'https://forum.freecodecamp.dev/srv/status',
          discourseUrl: 'https://forum.freecodecamp.dev/'
        },
      };
      const discourseEmbedInfo = discourseEmbedMap[hostname] ? discourseEmbedMap[hostname] : discourseEmbedMap['dev'];
      const { file, discourseUrl } = discourseEmbedInfo;

      function loadDiscourseComments() {
        var xhr = new XMLHttpRequest();
        var randomNum = Math.round(Math.random() * 10000);
        xhr.open('HEAD', file + '?rand=' + randomNum, true);
        xhr.send();
        xhr.addEventListener('readystatechange', processRequest, false);
        function processRequest(e) {
          if (xhr.readyState == 4) {
            if (xhr.status >= 200 && xhr.status < 304) {
              document.getElementById('discourse-comments').innerHTML = '';
              DiscourseEmbed = {
                discourseUrl,
                discourseEmbedUrl: 'https://www.freecodecamp.org/news/how-naive-bayes-classifiers-work/'
              };
              var d = document.createElement('script');
              d.type = 'text/javascript';
              d.async = true;
              d.src = discourseUrl + 'javascripts/embed.js';
              (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d);
            } else {
              document.getElementById('discourse-comments').innerHTML =
                '<div style="text-align: center;">Sorry, we could not load the comments. Please try again after some time.</div>';
            }
          }
        }
      }

      if (window && window.addEventListener) {
        // Create comments section
        const commentsDivHtml = `
          <div id='discourse-comments'>
            <button id='trigger-load-comments'>Show comments</button>
          </div>
        `;
        const fullContentSection = document.getElementsByClassName('post-full-content')[0];
        fullContentSection.insertAdjacentHTML('beforeend', commentsDivHtml);

        window.addEventListener('load', function () {
          document.getElementById('trigger-load-comments').onclick = loadDiscourseComments;
        });
      }
    }
  </script>
            </section>

        </article>
    </div>
</main>




        <footer class="site-footer">
    <div class="footer-container">
        <div class="footer-top">
            <div class="footer-desc-col">
                <p>
                    freeCodeCamp is a donor-supported tax-exempt 501(c)(3) nonprofit organization (United States Federal Tax Identification Number: 82-0779546)
                </p>
                <p>
                    Our mission: to help people learn to code for free. We accomplish this by creating thousands of videos, articles, and interactive coding lessons - all freely available to the public. We also have thousands of freeCodeCamp study groups around the world.
                </p>
                <p>
                    Donations to freeCodeCamp go toward our education initiatives, and help pay for servers, services, and staff.
                </p>
                <p class="footer-donation">
                    You can <a id="footer-donation" class="inline" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/donate/">make a tax-deductible donation here</a>.
                </p>
            </div>
            <div class="trending-guides">
                <div class="col-header">Trending Guides</div>
                <div class="trending-guides-row">
                    <div class="footer-col footer-col-1">
                        <a id="article0" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/what-is-docker-used-for-a-docker-container-tutorial-for-beginners/">What is Docker?</a>
                        <a id="article1" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/what-is-tcp-ip-layers-and-protocols-explained/">TCP/IP Model</a>
                        <a id="article2" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/rtf-file-what-is-the-rich-text-format/">RTF File</a>
                        <a id="article3" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/css-transition-examples/">CSS Transition</a>
                        <a id="article4" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-use-instagram-like-a-pro/">How to Use Instagram?</a>
                        <a id="article5" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/mbr-vs-gpt-whats-the-difference-between-an-mbr-partition-and-a-gpt-partition-solved/">MBR VS GPT</a>
                        <a id="article6" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-format-a-usb-drive-to-fat32-on-windows-10/">FAT32 Format</a>
                        <a id="article7" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/http-error-503-service-unavailable-explained-what-the-503-error-code-means/">Error 503 Code</a>
                        <a id="article8" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-find-and-edit-a-windows-hosts-file/">Windows Hosts File</a>
                        <a id="article9" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/mobi-to-pdf-how-to-convert-to-and-from-a-mobi-file/">Mobi to PDF</a>
                    </div>
                    <div class="footer-col footer-col-2">
                        <a id="article10" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/what-is-stem-the-meaning-of-an-acronym-youll-hear-a-lot-in-school/">What is STEM?</a>
                        <a id="article11" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/javascript-void-keyword-explained/">JavaScript Void 0</a>
                        <a id="article12" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/sql-delete-row-statement-examples/">SQL Delete Row</a>
                        <a id="article13" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/javascript-string-replace-example-with-regex/">JavaScript Replace</a>
                        <a id="article14" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/python-read-json-file-how-to-load-json-from-a-file-and-parse-dumps/">Python JSON Parser</a>
                        <a id="article15" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/cmd-delete-folder-how-to-remove-files-and-folders-in-windows/">cmd Delete Folder</a>
                        <a id="article16" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/what-is-nfc-near-field-communication-uses-chips-tags-and-readers-explained/">What is NFC?</a>
                        <a id="article17" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/what-is-the-correct-content-type-for-json-request-header-mime-type-explained/">Content Type JSON</a>
                        <a id="article18" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/heic-to-jpg-how-to-convert-images-on-a-mac/">Convert HEIC to JPG</a>
                        <a id="article19" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/generate-random-numbers-java/">Math Random Java</a>
                    </div>
                    <div class="footer-col footer-col-3">
                        <div class="footer-left">
                            <a id="article20" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-start-a-blog-with-wordpress/">WordPress for Beginners</a>
                            <a id="article21" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/qualitative-vs-quantitative-definition-research-methods-and-data/">Qualitative VS Quantitative</a>
                            <a id="article22" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/javascript-split-string-example/">JavaScript Split String</a>
                            <a id="article23" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-type-letters-with-accents-on-mac/">Accented Letters on Mac</a>
                            <a id="article24" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-find-a-windows-10-product-key/">Windows 10 Product Key</a>
                        </div>

                        <div class="footer-right">
                            <a id="article25" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/google-docs-landscape-tutorial-how-to-make-a-google-doc-landscape-orientation/">Google Docs Landscape</a>
                            <a id="article26" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/antimalware-service-executable-what-is-msmpeng-exe-and-why-is-it-running-in-windows-10/">Antimalware Executable</a>
                            <a id="article27" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/windows-10-start-menu-not-working-solved/">Windows 10 Start Menu</a>
                            <a id="article28" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/how-to-open-the-command-prompt-in-windows-10/">Windows 10 Command Line</a>
                            <a id="article29" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/google-account-recovery-change-gmail-password/">Google Account Recovery</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="footer-bottom">
            <div class="col-header">Our Nonprofit</div>
            <div class="footer-divider"></div>
            <div class="our-nonprofit">
                <a id="about" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/about/">About</a>
                <a id="alumni" rel="noopener noreferrer" target="_blank" href="https://www.linkedin.com/school/free-code-camp/people/">Alumni Network</a>
                <a id="open-source" rel="noopener noreferrer" target="_blank" href="https://github.com/freeCodeCamp/">Open Source</a>
                <a id="shop" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/shop/">Shop</a>
                <a id="support" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/support/">Support</a>
                <a id="sponsors" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/sponsors/">Sponsors</a>
                <a id="honesty" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/academic-honesty-policy/">Academic Honesty</a>
                <a id="coc" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/code-of-conduct/">Code of Conduct</a>
                <a id="privacy" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/privacy-policy/">Privacy Policy</a>
                <a id="tos" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/terms-of-service/">Terms of Service</a>
                <a id="copyright" rel="noopener noreferrer" target="_blank" href="https://www.freecodecamp.org/news/copyright-policy/">Copyright Policy</a>
            </div>
        </div>
    </div>
</footer>


    </div>

    <script>
        var images = document.querySelectorAll('.kg-gallery-image img');
        images.forEach(function (image) {
            var container = image.closest('.kg-gallery-image');
            var width = image.attributes.width.value;
            var height = image.attributes.height.value;
            var ratio = width / height;
            container.style.flex = ratio + ' 1 0%';
        })
    </script>

    <script src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous">
        </script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/jquery.fitvids.js"></script>

    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-unescaped-markup.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-markup-templating.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-bash.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-c.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-clojure.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-cpp.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-csharp.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-css.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-docker.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-elixir.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-erlang.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-git.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-go.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-graphql.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-haskell.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-java.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-javascript.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-json.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-jsx.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-kotlin.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-lua.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-markup.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-php.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-python.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-r.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-ruby.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-rust.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-scala.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-sql.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-swift.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-typescript.min.js"></script>
    <script type="text/javascript" src="./How Naive Bayes Classifiers Work – with Python Code Examples_files/prism-yaml.min.js"></script>

    <script>
    // Conditionally remove social-row based on the publication language setting
    const hideSocialRowList = ['zh-cn'];
    const socialRow = document.getElementsByClassName('social-row')[0];

    if (hideSocialRowList.includes(`en`)) socialRow.remove();
    else {
        const title = `How%20Naive%20Bayes%20Classifiers%20Work%20%E2%80%93%20with%20Python%20Code%20Examples`.replace(/'/g, '%27');
        const twitter = `@josejorgexl`;
        const url = window.location;
        const thanks = `Thank%20you%20%40josejorgexl%20for%20writing%20this%20helpful%20article.` +
            `%0A%0A${title}%0A%0A${url}`;
        const button = document.getElementById('tweet-btn');
        button.addEventListener('click', () => {
            if (twitter) {
                window.open(`https://twitter.com/intent/tweet?text=${thanks}`, `share-twitter`, `width=550, height=235`);
                return false;
            }
            else {
                window.open(`https://twitter.com/intent/tweet?text=${title}%0A%0A${url}`, `share-twitter`, `width=550, height=235`);
                return false;
            }
        });
    }
</script>

<script>
    const learnToCodeCtaAnchorEl = document.getElementById('learn-to-code-cta');

    learnToCodeCtaAnchorEl.href = main['learn-to-code-cta-url'];
</script>

<script>
    $(document).ready(function () {
        // Start fitVids
        var $postContent = $(".post-full-content");
        $postContent.fitVids();
        // End fitVids
    });
</script>

<script>
    const navForumAnchorEl = document.getElementById('nav-forum');
    const navDonateAnchorEl = document.getElementById('nav-donate');

    navForumAnchorEl.href = main['forum-url'];
    navDonateAnchorEl.href = main['donate-url'];
</script>

<script>
    const bannerAnchorEl = document.getElementById('banner');

    bannerAnchorEl.href = main['banner-url'];
</script>

<script>
    const { trending, ...otherUrls } = footer;
    const footerDonationAnchorEl = document.getElementById('footer-donation');

    Object.keys(trending).forEach(key => {
        const anchorId = key.replace(/link|title/, '');
        const trendingAnchorEl = document.getElementById(anchorId);

        if (key.includes('link')) {
            trendingAnchorEl.href = trending[key]
        } else if (key.includes('title')) {
            trendingAnchorEl.textContent = trending[key];
        }
    });

    Object.keys(otherUrls).forEach(key => {
        const footerAnchorEl = document.getElementById(key);

        footerAnchorEl.href = otherUrls[key];
    });

    footerDonationAnchorEl.href = main['donate-url'];
</script>


    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5D6RKKP"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->



</body></html>